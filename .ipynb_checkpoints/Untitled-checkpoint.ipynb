{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# preprocess\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "# for classifiers\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# for cross_validate\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Ignore Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseDataset(name):\n",
    "    dataPath = 'datasets/'\n",
    "    if name == 'diabetes':\n",
    "        colNames= ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "        df = pd.read_csv(dataPath + 'PIMA_Indiana_diabetes/pima-indians-diabetes.data.csv', names = colNames)\n",
    "        missCol = ['glucose','bp','skin','insulin','bmi']\n",
    "        for col in missCol:\n",
    "            df[col].replace([0,0.0], np.nan, inplace = True)\n",
    "                   \n",
    "#       convert 0 as missing values\n",
    "    elif name == 'breastCancer':\n",
    "        colNames = ['sampleCodeNumber', 'clumpThickness', 'uniformityCellSize', 'uniformityCellShape', 'marginalAdhesion', 'singleEpithelialCellSize', 'bareNuclei', 'blandChromatin', 'normalNucleoli', 'mitoses', 'label']\n",
    "        df = pd.read_csv(dataPath + 'BreastCancer/breast-cancer-wisconsin.data.txt', names = colNames)\n",
    "        df.replace(\"?\", np.nan, inplace= True)\n",
    "        df['bareNuclei'] = pd.to_numeric(df['bareNuclei'])\n",
    "        # making class labels as 0 (Benign) and 1 (Malignant)\n",
    "        df['label'] = df['label'].replace(2, 0)\n",
    "        df['label'] = df['label'].replace(4, 1)\n",
    "        missCol = ['bareNuclei']\n",
    "        k_knn = 7\n",
    "#         print pd.unique(df[missCol].values.ravel('K'))\n",
    "    elif name == 'parkinsons':\n",
    "        colNames= ['name','MDVP:Fo','MDVP:Fhi','MDVP:Flo','MDVP:Jitter(%)','MDVP:Jitter(Abs)','MDVP:RAP','MDVP:PPQ','Jitter:DDP','MDVP:Shimmer','MDVP:Shimmer(dB)','Shimmer:APQ3','Shimmer:APQ5','MDVP:APQ','Shimmer:DDA','NHR','HNR','label','RPDE','DFA','spread1','spread2','D2','PPE']\n",
    "        df=pd.read_csv(dataPath+'Parkinsons/parkinsons.data.txt',names=colNames)\n",
    "        missCol=[]\n",
    "        #no missing values\n",
    "        \n",
    "    elif name == 'BUPA':\n",
    "        #not given which one is infected\n",
    "        colNames = ['mcv', 'alkphos', 'sgpt','sgot','gammagt','drinks','label']\n",
    "        df = pd.read_csv(dataPath + 'BUPA(Liver)/bupa.data.txt',names = colNames )\n",
    "        df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "        df['Class'] = df['Class'].replace(1, 0)\n",
    "        df['Class'] = df['Class'].replace(2, 1)\n",
    "        missCol=[]\n",
    "        \n",
    "    elif name == 'Cleveland':\n",
    "        colNames= ['age','sex','cp','trestbps','chol','fbs','restecg'  ,'thalach', 'exang', 'oldpeak','slope','ca', 'thal','label']\n",
    "        df = pd.read_csv(dataPath + 'Cleveland(Heart)/processed.cleveland.data.txt',names = colNames)\n",
    "        df.replace (\"-9.0\",np.nan,inplace=True)\n",
    "        missCol = df.columns[df.isna().any()].tolist()\n",
    "        \n",
    "    elif name == 'Hepatitis':\n",
    "        colNames =['label','AGE','SEX','STEROID','ANTIVIRALS','FATIGUE','MALAISE','ANOREXIA','LIVER BIG','LIVER FIRM','SPLEEN PALPABLE','SPIDERS','ASCITES','VARICES','BILIRUBIN','ALK PHOSPHATE','SGOT','ALBUMIN','PROTIME','HISTOLOGY']\n",
    "        df = pd.read_csv(dataPath + 'Hepatitis/hepatitis.data.txt',names= colNames)\n",
    "        df.replace(\"?\",np.nan,inplace=True)\n",
    "        missCol= df.columns[df.isna().any()].tolist()\n",
    "        \n",
    "    elif name == 'ILPD':\n",
    "        colNames =['Age','Gender','TB','DB','Alkphos','SGPT','SGOT','TP','ALB','A/G','label']\n",
    "        df = pd.read_csv(dataPath + 'ILPD(Liver)/ILPD.csv',names= colNames)\n",
    "        print(df.shape)\n",
    "        df['Gender'] = df['Gender'].replace('Male', 0)\n",
    "        df['Gender'] = df['Gender'].replace('Female', 1)\n",
    "        missCol=['A/G']\n",
    "        k_knn = 0\n",
    "        \n",
    "    else:\n",
    "        print (\"NOT FOUND\")\n",
    "        return\n",
    "    return df, missCol, k_knn\n",
    "\n",
    "def normalizeData(df):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    for i in df.columns:\n",
    "        null_index = df[i].isnull()\n",
    "        df.loc[~null_index, [i]] = scaler.fit_transform(df.loc[~null_index, [i]])\n",
    "    return df\n",
    "\n",
    "def computeMissing(df,missCol, k = 5):\n",
    "    # get No Missing Data Rows \n",
    "#     print pd.unique(df[missCol].values.ravel('K'))\n",
    "    if missCol == []:\n",
    "        return df\n",
    "    no_missing_df = df.dropna(axis=0, how='any')\n",
    "#     print(no_missing_df.shape, df.shape)\n",
    "#     print no_missing_df.head()\n",
    "    # get Missing Data Rows \n",
    "    missing_df = pd.DataFrame(df[~df.isin(no_missing_df).all(1)])\n",
    "#     print missing_df.head()\n",
    "    # removed last column\n",
    "    data = no_missing_df.drop(['label'], axis = 1, inplace = False)\n",
    "    # Create the knn model.\n",
    "    y_columns = missCol\n",
    "    x_columns = data.columns.tolist()\n",
    "#     print y_columns\n",
    "    for col in y_columns:\n",
    "        x_columns.remove(col)\n",
    "        \n",
    "    # Look at the five closest neighbors.\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    # Fit the model on the training data.\n",
    "    knn.fit(no_missing_df[x_columns], no_missing_df[y_columns])\n",
    "    # Make point predictions on the test set using the fit model.\n",
    "    predictions = knn.predict(missing_df[x_columns])\n",
    "    missing_df[y_columns] = predictions\n",
    "    no_missing_df = no_missing_df.append(missing_df)\n",
    "    return no_missing_df\n",
    "\n",
    "def removeOutliers(df):\n",
    "    maskall = {}\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    \n",
    "    for col in df.columns[:-1]:\n",
    "        IQR = Q3[col] - Q1[col]\n",
    "        mask = df[col].between(Q1[col] - 1.5*IQR, Q3[col] + 1.5*IQR, inclusive=True)\n",
    "        maskall[col] =mask\n",
    "        df = df[mask]\n",
    "#         print df.shape\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_Compute(X,y, n):\n",
    "    pca = PCA(n_components= n, svd_solver='full')\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    return X,y\n",
    "def Fscore_Compute(X,y, n = 5):\n",
    "    selector = SelectKBest(f_classif, k=n)\n",
    "    selector.fit(X,y)\n",
    "    X = selector.transform(X)\n",
    "    print (selector.scores_, X.shape)\n",
    "    return X,y\n",
    "def featureSelection(X,y,k, choice = 0):\n",
    "    if choice == 1:\n",
    "        return Fscore_Compute(X,y,k)\n",
    "    return PCA_Compute(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   4.51505927  733.20697841 1408.52721279 1419.30553012  657.79369959\n",
      "  608.71955539 1417.3134106   933.28729668  717.62804135  152.04023895] (699, 10)\n"
     ]
    }
   ],
   "source": [
    "df, missCol, k_knn = chooseDataset('breastCancer')\n",
    "df = normalizeData(df)\n",
    "df = computeMissing(df, missCol)\n",
    "df2 = removeOutliers(df)\n",
    "label = df['label']\n",
    "df.drop('label', axis=1, inplace=True)\n",
    "X, y = df, label\n",
    "X,y = featureSelection(X,y,X.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQDA(k=10):\n",
    "    clf = QDA(priors=None, reg_param=0.0)\n",
    "    return \"QDA\",clf\n",
    "\n",
    "def getLR(k=10):\n",
    "    # LogisticRegressionCV(class_weight='balanced',scoring='roc_auc',n_jobs=10, max_iter=10000, verbose=1,cv=10)\n",
    "    regr = LogisticRegressionCV(class_weight='balanced',scoring='roc_auc', max_iter=10000, verbose=1,cv=10)\n",
    "    return \"LR\",regr\n",
    "\n",
    "def getSVM(k=10):\n",
    "    svc = svm.SVC(C=1, kernel='linear')\n",
    "    return \"SVM\",svc\n",
    "\n",
    "def getKNN(k_knn,k=10):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k_knn, algorithm = 'ball_tree', leaf_size=500)\n",
    "    return \"KNN\", knn\n",
    "\n",
    "def getNaivebayes(k=10):    \n",
    "    clf = GaussianNB()\n",
    "    return \"NB\",clf\n",
    "\n",
    "def getDecisionTreeinfogain(k=10):\n",
    "    clf = DecisionTreeClassifier(class_weight=None, criterion='entropy', random_state=100, splitter='best')\n",
    "    return \"DT-I\",clf\n",
    "\n",
    "def getDecisionTreegini(k=10):\n",
    "    #X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    clf = DecisionTreeClassifier(class_weight=None, criterion='gini',random_state=100, splitter='best')\n",
    "    return \"DT-G\",clf\n",
    "\n",
    "def getRandomForest(numtrees =10,k=10):\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    return \"RF\", clf\n",
    "\n",
    "def getAdaBoost(estimators=100):\n",
    "    clf = AdaBoostClassifier(n_estimators=estimators)\n",
    "    return \"AB\",clf\n",
    "\n",
    "\n",
    "def getBaggingClassifier(poorclf=KNeighborsClassifier()):\n",
    "    bagging = BaggingClassifier(poorclf,max_samples=0.5, max_features=0.5)\n",
    "    return \"BG\",bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMV_Layer1():\n",
    "    clf1 = QDA(priors=None, reg_param=0.0)\n",
    "    clf2 = LogisticRegression()\n",
    "    clf3 = GaussianNB()\n",
    "    clf = VotingClassifier(estimators=[('QDA', clf1), ('LR', clf2), ('NB', clf3)], voting='hard') \n",
    "    return clf\n",
    "\n",
    "def HMV_Layer2(clf_prev, k):\n",
    "    clf1 = KNeighborsClassifier(n_neighbors = k, algorithm = 'ball_tree', leaf_size=500)\n",
    "    clf2 = svm.SVC(C=1, kernel='linear')\n",
    "    clf = VotingClassifier(estimators=[('KNN', clf1), ('SVM', clf2), ('LAYER1', clf_prev)], voting='hard') \n",
    "    return clf\n",
    "\n",
    "def HMV_Layer3(clf_prev):\n",
    "    clf1 = DecisionTreeClassifier(class_weight=None, criterion='entropy', random_state=100, splitter='best')\n",
    "    clf2 = DecisionTreeClassifier(class_weight=None, criterion='gini', random_state=100, splitter='best')\n",
    "    clf = VotingClassifier(estimators=[('DTIG', clf1), ('DTGI', clf2), ('LAYER2', clf_prev)], voting='hard')\n",
    "    return clf\n",
    "def getHMV(k_nn):\n",
    "    lay1 = HMV_Layer1()\n",
    "    lay2 = HMV_Layer2(lay1, k_knn)\n",
    "    lay3 = HMV_Layer3(lay2)\n",
    "    return \"HMV\",lay3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "classifierlabels = []\n",
    "label, clf = getQDA()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getLR()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getSVM()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getKNN(k_knn)\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getNaivebayes()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getDecisionTreeinfogain()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getDecisionTreegini()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getRandomForest()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getAdaBoost()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getBaggingClassifier()\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n",
    "label, clf = getHMV(k_knn)\n",
    "classifiers.append(clf)\n",
    "classifierlabels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "KNN\n",
      "NB\n",
      "DT-I\n",
      "DT-G\n",
      "RF\n",
      "AB\n",
      "BG\n",
      "HMV\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "accuracystd = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "precision = []\n",
    "\n",
    "for i in range(len(classifierlabels)):\n",
    "    # print('\\n\\n\\n')\n",
    "    print(classifierlabels[i])\n",
    "    kf = KFold(n_splits=5)\n",
    "    clf = classifiers[i]\n",
    "    acc = []\n",
    "    sen = []\n",
    "    spec = []\n",
    "    prec = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        # print (classification_report(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sen.append ( tp / (tp + fn) )\n",
    "        spec.append ( tn / (tn + fp) )\n",
    "        acc.append( (tn + tp)/ (tn + tp + fn + fp) )\n",
    "        prec.append ( tp/ (tp + fp) )\n",
    "    accuracy.append(np.array(acc).mean())\n",
    "    sensitivity.append(np.array(sen).mean())\n",
    "    specificity.append(np.array(spec).mean())\n",
    "    precision.append(np.array(prec).mean())\n",
    "    accuracystd.append(np.array(acc).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcHWWd7/HPt09vWYGQToAshCURQkSEJggoIApGRRB1gCgCd0bQcdAZHbgXxjvq4Dij41XmKlEnOojMiOAwLEGQgAuCLJoOECAJIQtLmi1NNhK6k95+88ephkPndPr06dN9uru+79erX+mqeqqepzrnfE/VU1XPUURgZmbpUFHuBpiZ2eBx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIg59M7MUqSx3A7qbOHFizJgxo9zNMDMbVpYuXfpKRNT1Vm7Ihf6MGTNoaGgodzPMzIYVSc8WUs7dO2ZmKVJQ6EuaJ2mVpDWSLuuhzFmSVkhaLum6nPn/ksxbKem7klSqxpuZWd/02r0jKQMsAE4BGoElkhZFxIqcMjOBy4HjI2KzpEnJ/OOA44HDk6J/AE4E7inlTpiZWWEKOdKfC6yJiHUR0QpcD5zRrcyFwIKI2AwQERuS+QHUAtVADVAFvFyKhpuZWd8VEvpTgPU5043JvFyzgFmS7pf0kKR5ABHxIPA74MXkZ3FErOx/s83MrBiF3L2Trw+++zevVAIzgZOAqcB9kuYAE4FDk3kAd0s6ISLufVMF0kXARQDTp08vuPFmZtY3hRzpNwLTcqanAi/kKXNrRLRFxNPAKrIfAmcCD0XE9ojYDvwKeEf3CiJiYUTUR0R9XV2vt5mamVmRCgn9JcBMSQdIqgbOARZ1K3ML8G4ASRPJdvesA54DTpRUKamK7EVcd++YmZVJr6EfEe3AxcBisoH9i4hYLukKSacnxRYDGyWtINuHf2lEbARuBNYCjwPLgGURcdsA7IeZmRVAQ+2L0evr68NP5JqZ9Y2kpRFR31s5P5FrZpYiDn0zsxRx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIg59M7MUceibmaWIQ9/MLEUc+mZmKeLQNzNLEYe+mVmKOPTNzFLEoW9mliIOfTOzFHHom5mliEPfzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvZpYiBYW+pHmSVklaI+myHsqcJWmFpOWSrsuZP13SXZJWJstnlKbpZmbWV5W9FZCUARYApwCNwBJJiyJiRU6ZmcDlwPERsVnSpJxNXAt8PSLuljQW6CzpHpiZWcEKOdKfC6yJiHUR0QpcD5zRrcyFwIKI2AwQERsAJM0GKiPi7mT+9ohoLlnrzcysTwoJ/SnA+pzpxmRerlnALEn3S3pI0ryc+Vsk3STpEUnfSs4czMysDAoJfeWZF92mK4GZwEnAfODHkvZM5r8LuAQ4GjgQuGCXCqSLJDVIamhqaiq48WZm1jeFhH4jMC1neirwQp4yt0ZEW0Q8Dawi+yHQCDySdA21A7cAR3avICIWRkR9RNTX1dUVsx9mZlaAQkJ/CTBT0gGSqoFzgEXdytwCvBtA0kSy3TrrknX3ktSV5CcDKzAzMwAigmXrt3DX8pf447qNtHcM7L0uvd69ExHtki4GFgMZ4OqIWC7pCqAhIhYly06VtALoAC6NiI0Aki4BfiNJwFLgRwO0L2Zmw8qtjzzPN+58kq0tbWQqRARkKsSnTzyQz5xwEBUV+XrX+0cR3bvny6u+vj4aGhrK3QwzswG18N61XHn3U7S07XpkP6oqw/sOm8yVZx9B9ni5d5KWRkR9b+X8RK6Z2SB7bmMz374rf+ADtLR1cNeKl/ntkxtKXrdD38xskP3kgafp7KWXpbm1gx/+fm3J63bom5kNsvueaqKto/eu9UfXbyl53Q59M7NBVkDeAzAQl1wd+mZmg+yIaXuSKeAC7YF1Y0pet0PfzGyQ/cU7D6C6cvfxO6o6w2dOPKjkdTv0zcwG2Zwpe/Cht+3LqKr8Q5HVVFZwyD7j+NDb9it53Q59M7My+MZHDuf842ZQW1XB6OoMmQoYVVVBTWUFpx42mes+9Q6qMqWPaD+cZWZWRtt3tnPX8pd4+dWdjB9Vyamz96FuXE2ft1Pow1m9DsNgZmYDZ2xNJR85cuqg1efuHTOzFHHom5mliEPfzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvZpYiDn0zsxRx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIgWFvqR5klZJWiPpsh7KnCVphaTlkq7rtmy8pOclXVWKRpuZWXF6/eYsSRlgAXAK0AgskbQoIlbklJkJXA4cHxGbJU3qtpmvAb8vXbPNzKwYhXxd4lxgTUSsA5B0PXAGsCKnzIXAgojYDBARG7oWSDoKmAzcCfT6/Y1mQ01E8PBzm1n67GZGVVfyvsMmM2lcbbmbZVaUQkJ/CrA+Z7oROKZbmVkAku4HMsBXI+JOSRXAt4FPAu/pf3PNBteW5lbO/fc/sq7pNVrbO6nMiH/85Qo+d/LBXHzyzHI3z6zPCgl95ZkXebYzEzgJmArcJ2kOcC5wR0Ssl/JtJqlAugi4CGD69OkFNMlscHz6P5ey6qVttHVkX/Ltndl/F/xuLQdPGsu8OfuWs3lmfVbIhdxGYFrO9FTghTxlbo2Itoh4GlhF9kPgWOBiSc8A/w84T9I3ulcQEQsjoj4i6uvq6orYDbPSW9e0nWXPbXk98HO1tHXw3d+sKUOrzPqnkNBfAsyUdICkauAcYFG3MrcA7waQNJFsd8+6iPhEREyPiBnAJcC1EZH37h+zoebJl7ZRmen5LbK2afsgtsasNHoN/YhoBy4GFgMrgV9ExHJJV0g6PSm2GNgoaQXwO+DSiNg4UI02GwwTxlQTu/RkvmFcbSG9o2ZDS0Gv2oi4A7ij27wv5/wewBeTn562cQ1wTTGNNCuHo2dMoLYyw2s7O3ZZVlNZwfy5vv5kw4+fyDXrQaZCXPXxIxlVlSG3l2dUVQUzJo7hMyceVL7GmRXJ56dmu3HsQXtz++ffycJ71/HA2o2Mqc5wztxpnFU/nVHVmXI3z6zPHPr91NEZNDyziS0tbUzdaxSH7bdHuZtkJXZg3Vi+8dHDy90Ms5Jw6PfD9X96jm/e+SStHZ0I0dEZ7LNHLd/62OHUz5hQ7uaZme3CffpF+sn9T/MPt61gc3Mbr+3sYPvOdlraOnj6ldc499//xNJnN5W7iWZmu3DoF2Hbjja+eeeTtLTtelcHwI62Dv7u5icGuVVmZr1z904R7nj8RSp2M6wEwLMbX2PNhu0cPGnsILXKzIrV2Rncuux5rn3gWba2tHH8wRO56IQDmTZhdLmbVnIO/SI8v7mF5tb8R/ldqjIVvLClxaFvNsRFBJ/92cPc+1QTzcnZ+3ObmrnpkUZu/MxxHLrv+DK3sLTcvVOECWOqqa3c/Z+uozOYMKZ6kFpkZsX6w5pXuHf1G4EP2YH1XtvZweU3PV7Glg0Mh34RPnj4frt5OD9rz9FVHLbfyDpCMBuJbn74+R7P3Je/sJWtLW2D3KKB5dAvQt24GubPnc6oqvwP59RWVfDl02azu+GkzWxoaO3o3O3yjs7eDvGGF4d+kb582mw+fsx0qisrGFWVobJCjKnOMKYmwz+d+VaPs242THzgrfsyuoenq6dPGD3iuml9IbdIFRXi70+bzcXvPpjFy196/Ync9x46mdoezgDMbOg5ZfZkDqobw1Mvb2dn+xtH/bVVFXztjDllbNnAUHaAzKGjvr4+Ghoayt0MM0uRltYOvvfb1dywZD2vtbZzxLQ9ufR9h3DU/nuVu2kFk7Q0Inr9HnKHvpnZCFBo6LtP38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUmRE3Ke/o62D2x97kTueeJGI7H23ZxyxH6OrR8TuWaK9o5P7Vr/CC1tbmLH3GI49cG8qKvzUs1lfDPtUXL+pmY/98AG27Wh/ffyMh9Zt5FuLV/GLTx/rUS5HiIZnNnHhtQ20dnTS0RlkJMbVVnHNnx/NIft4jCOzQg3r7p2I4IKf/ImmbTvfNGBSc2sHm19r5dwfPzTixs1Ioxe3tnDe1X96/VvKdrR18lprBy+9uoOz/+0htu0YWQNimQ2kYR36Dc9u5sWtO8iX6wFs29HO75/aMOjtstK65v5naO9hUKy2jk7+e2njILfIbPga1qG/bP0W2nYzQt5rrR0sW79lEFtkA+GBtRtp7ch/xtbc2sEDazcOcovMhq+CQl/SPEmrJK2RdFkPZc6StELScknXJfOOkPRgMu8xSWeXsvGjqrOjW/akqkKM8sXcYW98bc//hwLGj6oavMaYDXO9hr6kDLAAeD8wG5gvaXa3MjOBy4HjI+Iw4G+SRc3Aecm8ecC/StqzVI1/76GT6eEAEMiOhDnvsH1KVZ2Vydlzp/c49O2o6gwfO2rqILfIbPgq5Eh/LrAmItZFRCtwPXBGtzIXAgsiYjNARGxI/n0qIlYnv78AbADqStX4yeNrObt+Wt4vMxlVlWHeYfswY+KYUlVnZfL+Oftw6L7jd/mKylFVFbzz4Ikcc8CEMrXMbPgpJPSnAOtzphuTeblmAbMk3S/pIUnzum9E0lygGlhbbGPz+YfTD+P842YwqirDuJpKxtVUUlNZwdlHT+PbZ72tlFVZmVRlKvjZp47hL086iL3HVFMh2Gd8LX976lv4wblH+RvKzPqg16GVJf0Z8L6I+FQy/UlgbkR8LqfML4E24CxgKnAfMCcitiTL9wXuAc6PiIfy1HERcBHA9OnTj3r22Wf7vCPNre088twWOiM4YtqejKt1P6+ZpUehQysXcpWzEZiWMz0VeCFPmYciog14WtIqYCawRNJ44Hbg/+YLfICIWAgshOx4+gW0aRejqys5/uCJxaxqZpYahYT+EmCmpAOA54FzgI93K3MLMB+4RtJEst096yRVAzcD10bEf5Wu2WY2Em1pbmXhvev41RMvMbo6w8ePmc45R08n4+E2SqbX0I+IdkkXA4uBDHB1RCyXdAXQEBGLkmWnSloBdACXRsRGSecCJwB7S7og2eQFEfHoQOyMmQ1fW1va+OB376Np287Xn8v4x1+u5J5VTSz8pK/dlIq/LtHMhoSrfrua7/12zZu+nByyd+L97MJjOHL68Pm+2nLw1yWa2bBy14qXdwl8gJ3tHdy/+pUytGhkcuib2ZCwRw9PVldlKhi7m6eyrW8c+mY2JHzyHfvnffJawGmH7zf4DRqhHPpmNiScMnsyZx89jZrKCmoqKxhdnaG2qoIrzz6CunE15W7eiOFzJjMbEiTxlQ8dxvnHzuDe1U3UVmU4dfZk9hxdXe6mjSgOfTMbUmZMHOMxswaQu3fMzFLEoW9mliIOfTOzFHHom5mliEPfzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvZpYiDn0zsxRx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIg59M7MUceibmaVIQaEvaZ6kVZLWSLqshzJnSVohabmk63Lmny9pdfJzfqkabmZmfVfZWwFJGWABcArQCCyRtCgiVuSUmQlcDhwfEZslTUrmTwC+AtQDASxN1t1c+l0xM7PeFHKkPxdYExHrIqIVuB44o1uZC4EFXWEeERuS+e8D7o6ITcmyu4F5pWm6mZn1VSGhPwVYnzPdmMzLNQuYJel+SQ9JmteHdZF0kaQGSQ1NTU2Ft97MzPqkkNBXnnnRbboSmAmcBMwHfixpzwLXJSIWRkR9RNTX1dUV0CQzMytGIaHfCEzLmZ4KvJCnzK0R0RYRTwOryH4IFLKumZkNkkJCfwkwU9IBkqqBc4BF3crcArwbQNJEst0964DFwKmS9pK0F3BqMs/MzMqg17t3IqJd0sVkwzoDXB0RyyVdATRExCLeCPcVQAdwaURsBJD0NbIfHABXRMSmgdgRMzPrnSJ26WIvq/r6+mhoaCh3M8zMhhVJSyOivrdyfiLXzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvRensDDo6h9adX2bWu17v0zfLtWbDNr5++0rufeoVOgneut8eXPb+Qzju4InlbpqZFcBH+sPYqzvaeLxxK+uatjMYz1us2bCNMxbczz2rmuiIIAIee34rf/7TJfx6xcsDXr+Z9Z+P9IehV3e08eVblvOrJ16kKlNBR2cwaVwNXzl9NicfMnnA6v2n25+keWfHLiPm7Wjr5Eu3PM7Jh0yioiLfGHtmNlT4SH+YaWnt4CPff4A7Hn+Rne2dbN/ZTktbB89uauazP3uYOx4fmPHsIoLfr27adYjUxLYd7azesH1A6jaz0nHoDzP//fB6nt/cTGtH5y7LdrR18qWbnxiQC6ydAZ276UKSoC1Pm2z46uwMtu1o8wX7EcbdO8PMTx98lpa2nsO1rSP449MbOe6g0l5YzVSIw6fswbLGrXmXV0jMmjyupHVaeexs7+DKu5/iPx96jp3tHVRlKjjn6Gn873mHUFuVKXfzrJ98pD/MbH6ttZcSwaZeyxTnsvcfSm3Vri+ZUVUZ/vo9M6mu9MtpuIsILrj6T1xz/zNs39lOW0fQ3NrBz/74HPN/9JCP+kcAv0uHmf33HrPb5Z0B+0/YfZliHXvQ3nz/E0eyz/haRldnGFOTYVxtJX976iz+4p0HDEidNrgeWLuRZY1b2dH+5rPJne2drHppG/es2tDDmjZcuHtnmLnwXQew8sVXaW7tyLt88vha5kwZP2D1n3zIZB68fBJrNmxnZ3snsyaP8xH+CHLbshd6fG01t3Zwy6PP855DB+4OMRt4frcOM6fO3ocTZ9UxqlvfaoVgTE2G781/O9LA3jYpiZmTxzFnyh4O/BGmvZfum7YOd+8Md37HDjMVFWLBx4/kyx+azf57j0aC2soKPnzEFG7/3LuYM2WPcjfRhrH3HjqZMdX5L9aOqc7w/jn7DHKLrNTcvTMMVVSI+XOnM3/udCJiwI/sLT3ee+gk9tmjluc2Nb/pqL6yQkwYW808h/6w5yP9Yc6Bb6VUmangxs8cx0lvmURNZQVjayqprqzg+IMncvNnj6em0rdsDnc+0jezN9lrTDU/Oq+eTa+18sKWFvbZo5aJY2vK3SwrEYe+meU1YUw1E8ZUl7sZVmLu3jEzSxGHvplZijj0zcxSxKFvZpYiBYW+pHmSVklaI+myPMsvkNQk6dHk51M5y/5F0nJJKyV9V77H0MysbHq9e0dSBlgAnAI0AkskLYqIFd2K3hARF3db9zjgeODwZNYfgBOBe/rZbjMzK0IhR/pzgTURsS4iWoHrgTMK3H4AtUA1UANUAf4yVTOzMikk9KcA63OmG5N53X1U0mOSbpQ0DSAiHgR+B7yY/CyOiJX9bLOZmRWpkNDP1wfffai924AZEXE48GvgpwCSDgYOBaaS/aA4WdIJu1QgXSSpQVJDU1NTX9pvZmZ9UEjoNwLTcqanAm/69u2I2BgRO5PJHwFHJb+fCTwUEdsjYjvwK+Ad3SuIiIURUR8R9XV1dX3dBzMzK1Ahob8EmCnpAEnVwDnAotwCkvbNmTwd6OrCeQ44UVKlpCqyF3HdvWNmVia93r0TEe2SLgYWAxng6ohYLukKoCEiFgGfl3Q60A5sAi5IVr8ROBl4nGyX0J0RcVvpd8PMzAqhiKH1TTj19fXR0NBQ7maYmQ0rkpZGRH1v5TzKptkQ9sCaV/jB79eypbmNM98+hU8euz9VGT9Ib8Vz6JsNUYufeJG/uWEZLW3ZLypfvWEbS57ZxA/OPaqXNc165kMGsyHqm3euej3wAXa0dfLbJzewflNzGVtlw51D32yIeunVHbvMq66s4PktLWVojY0UDn2zIWrujAlUdHs0sq2jkzlT9ihPg2xEcOibDVFXnDGHvUZXM6Ymw6iqCmoqK/j6h9/K2BpfirPi+dVjNkRN33s09192Mr9e+TKvtrTz7kPq2HePUeVulg1zDn2zIay2KsNph+9X7mbYCOLuHTOzFHHom5mliEPfzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvZpYiDn0zsxRx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIg59M7MUceibmaVIQaEvaZ6kVZLWSLosz/ILJDVJejT5+VTOsumS7pK0UtIKSTNK13wzM+uLXr8jV1IGWACcAjQCSyQtiogV3YreEBEX59nEtcDXI+JuSWOBzv422szMilPIkf5cYE1ErIuIVuB64IxCNi5pNlAZEXcDRMT2iGguurVmZtYvhYT+FGB9znRjMq+7j0p6TNKNkqYl82YBWyTdJOkRSd9KzhzeRNJFkhokNTQ1NfV5J8zMrDCFhL7yzItu07cBMyLicODXwE+T+ZXAu4BLgKOBA4ELdtlYxMKIqI+I+rq6ugKbbmZmfVVI6DcC03KmpwIv5BaIiI0RsTOZ/BFwVM66jyRdQ+3ALcCR/WuymZkVq5DQXwLMlHSApGrgHGBRbgFJ++ZMng6szFl3L0ldh+8nA90vAJuZ2SDp9e6diGiXdDGwGMgAV0fEcklXAA0RsQj4vKTTgXZgE0kXTkR0SLoE+I0kAUvJngmYmVkZKKJ793x5SWoCnu3HJiYCr5SoOcOh3nLWnbZ6y1m393nk19vfuvePiF4vig650O8vSQ0RUZ+WestZd9rqLWfd3ueRX+9g1e1hGMzMUsShb2aWIiMx9BemrN5y1p22estZt/d55Nc7KHWPuD59MzPr2Ug80jczsx4M69CXdKakkHRIMj1DUksyvPMySQ9IekuJ6+zI2f7Dko7LWTZT0i8lrZW0VNLvJJ3QjzqWJ/V8UVKFpPflDF+9PRnu+lFJ1/awnS9KelLS48l2viOparDaIOkaSR/rw35v7zZ9gaSrkt+/mvxfH5yz/AvJvPqkrk93W//Dku7oa92SPiBpdTIs+FclNUua1EPZkPTtnOlLJH210H3urS05874q6fnkb71C0vz+1JFn+z3uR7e6n5T0A0lFZ4ekqZJuTf7G6yRdJalG0kmStio7TtcqSfdKOi3P+ssk/bzY+rttq+t1/oSk2yTtmczPzZKun+p+1POl5L30WLKtX0n6525ljpC0Mvn9GUn3dVv+qKQnim1Dl2Ed+sB84A9knxLusjYijoiIt5EdA+jvSlxnS872Lwf+GUBSLXA7sDAiDoqIo4DPkR1vqNg6DiM7pPUHgK9ExOJk/hFAA/CJZPq87huQ9BngVOAdEfFWsmMfbQBGDVYbBsDjvPn/+mO88YT3z7stI5nuUzhIeg/wPWBeRDyXzH4F+NseVtkJfETSxL7UU6Qrk7/7GcC/FfoBXqDe9qOr7tnAW4ETi6lEkoCbgFsiYiYwk+xr8l+SIvdFxNsj4i3A54Grkv+TrvUPJZtbJ0gaU0wbuul6nc8h+2DpX+Us68qSrp/WYiqQdCxwGnBkMj7Ze4FvAGd3K3oOcF3O9Dglg1cm+10Swzb0lR2b/3jgL9j1zd5lPLB5AJuRu/1PAA8mTygDEBFPRMQ1/akgIjYAFwEXJ2+YQn0J+MuI2JJspzUivhERrw5iG0rtFpJhvSUdCGwFuoZl/TVwiJIhQSSNJvvmuqXQjUt6F9knxj8YEWtzFl0NnC1pQp7V2slefPtC33aleBGxGmgG9irhZgvdj2qgluLfVycDOyLiJ5B9aj+p8zxgbG7BiHgUuALI/Z6OjwP/AdxFdsiXUnqQ/CMI99e+wCtd45NFxCsR8XuyIxAfk1PuLLJD13f5BW98MMynjwcwPRm2oQ98GLgzIp4CNknqGsjtoOQ0aC3wReA7Ja53VNdpLvBj4GvJ/MOAh0tcFwARsY7s/9Wk3soCSBoHjI2Ip8vVhiJ1/W0fldT1hs/1KrBe0hyyb4IbctrXQfYI8qxk1unA7yJiW4F11wC3Ah+OiCe7LdtONvj/uod1FwCfkLRHgXX1S/JaX518GJfS7vbjC8n/yYvAU0kgF+MwssOxvC45EHkGODhP+YeBQ3Kmzyb7//5zsq+BklB2yPf38OZxxQ7KeT0u6Mfm7wKmSXpK0vcldZ0lvX52KukdwMbkA73LjcBHkt8/RHY0434bzqE/nzc+Fa/njRdA1ynZQcDfUPpboLpOBw8B5gHX5jv6lXRz0k94U4nq7csRtsgZ/lpv9MM/o5xrEAPchmJ0/W27uo++nKfM9WTfKB8Gbu62LLeLp69dO23AA2TPHPP5LnC+pPHdFyShdS3Z7oiB9AVJq4A/Al8t9cZ72Y+u7p1JwBhJPZ1d9+ZNr81u83sqn/1FOhpoiohngd8AR0rq79nOqOTDbCMwAbg7Z1lu985f5V+9dxGxnezIwxeRPTO9QdIFZF/LH0uuj+R7vW4CNid/65Vkz+76bViGvqS9yZ4m/ljSM8ClZI8Aur9wFgF9vpBaqIh4kOxYGXXAcnKGjY6IM8kOPJevS6BPkq6MDrJ98j2V+UkS7Hckb97XJB2QtGVx8oZ9guzp+YC3oZg6CnQb8EnguTxdVfcD+0p6G3Ac0Jd2dJI9Szha0i7XgZJusuuAz/aw/r+S/cAoRT9zT65M+rrPJnuwUTsAdex2PyKiDbiT4t9Xy4E3DTOQfJBOBlblKf923hi1dz7ZLrxngLVku1c/WmQ7urQk7439yb43ig733YmIjoi4JyK+Qra76qMRsZ7sGc6JZPfjF3lWvYHsGVhJunZgmIY+2Qt410bE/hExIyKmAU+THes/1zvJvjgGhLJ3DWXIHiVcBxyv7GijXUaXoI464IfAVbGbhyoi4n8lRyQfSGb9M/CDnLsRRLYvdjDbUHIR0QL8H+DreZYF2TfOT4E7ImJHH7fdTPaC2yck5Tvi/w7wafKMThsRm5K6ezpTKJmIuInsRfTzB2Dbu92P5HV0HMW/r34DjJZ0XrK9DPBt4CqgpVtdhwN/DyxIjob/DDg8ec/PIHt9pyRdPBGxlewZziUlvkCOpLdImpkz6wjeGFTy58CVZM8qGvOsfjPZi9yLS9WeXodWHqLmk736neu/yd6pc1Byuia1YuQqAAABK0lEQVSgFfhUievuOh0kqeP8pD+5Jbm97DuS/hV4GdgG/GM/6qgie4HtP+j7tYkfkP3Q+aOknWT7pe8HHhnENgyIiLh+N4t/TvbM77Iit71J0jzgXkmvdFv2iqSb6fli57d580XHYo2WlBsA+f7uVwDXSfpRRHSWoM5c+fbjC5LOJft6eAz4fjEbjoiQdCbZIP97smfJN0TE1yWdBLxL0iNkX7sbgM9HxG+SZc9HxPM5m7sXmC1p34h4sZj2dGvbI5KWke1qua+38n0wFvhecgDWDqwh29UD8F/A/yd7p1++Nm0DvglQqnso/ESumZVNco3p58BHImJpb+Wt/xz6ZmYpMlz79M3MrAgOfTOzFHHom5mliEPfzCxFHPpmZini0DczSxGHvplZivwP1/b/UBoiErcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f977a532358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  QDA Accuracy:  0.616628982528263 (+/- 0.039215988286393666 %) Precision:  0.3699233468743451  Sensitivity:  0.22356649111257404  Specificity:  0.8099752291809269 \n",
      "\n",
      "Classifier:  LR Accuracy:  0.5751284686536485 (+/- 0.026985669264623285 %) Precision:  0.3459476071419478  Sensitivity:  0.3600222185648453  Specificity:  0.653443152694722 \n",
      "\n",
      "Classifier:  SVM Accuracy:  0.6553545734840698 (+/- 0.09605500337540084 %) Precision:  nan  Sensitivity:  0.0  Specificity:  1.0 \n",
      "\n",
      "Classifier:  KNN Accuracy:  0.638180883864337 (+/- 0.05329649270851825 %) Precision:  0.45486860387041883  Sensitivity:  0.20260821263989465  Specificity:  0.8678188502307286 \n",
      "\n",
      "Classifier:  NB Accuracy:  0.5880472764645426 (+/- 0.05292124788560115 %) Precision:  0.3598595382920326  Sensitivity:  0.24080192560895322  Specificity:  0.7574295212272035 \n",
      "\n",
      "Classifier:  DT-I Accuracy:  0.5909352517985611 (+/- 0.052541668785049636 %) Precision:  0.37592962919311834  Sensitivity:  0.28881542132982224  Specificity:  0.7447516992905693 \n",
      "\n",
      "Classifier:  DT-G Accuracy:  0.5895991778006167 (+/- 0.06753213885304855 %) Precision:  0.3768670811652997  Sensitivity:  0.32530529953917053  Specificity:  0.7236499859387353 \n",
      "\n",
      "Classifier:  RF Accuracy:  0.6309866392600206 (+/- 0.0456199580244502 %) Precision:  0.3940056022408963  Sensitivity:  0.1877703258722844  Specificity:  0.8529017497873124 \n",
      "\n",
      "Classifier:  AB Accuracy:  0.6224357656731758 (+/- 0.06372040745282384 %) Precision:  0.3336781609195402  Sensitivity:  0.11323897300855826  Specificity:  0.8836877833256395 \n",
      "\n",
      "Classifier:  BG Accuracy:  0.6324357656731758 (+/- 0.0775343473080826 %) Precision:  0.30333333333333334  Sensitivity:  0.04848378867676102  Specificity:  0.9439739963882892 \n",
      "\n",
      "Classifier:  HMV Accuracy:  0.6224460431654676 (+/- 0.054911742051624475 %) Precision:  0.3952696555395206  Sensitivity:  0.2205776826859776  Specificity:  0.8297279896990183 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "showstd = []\n",
    "for  i in accuracystd:\n",
    "    showstd.append(i*1000)\n",
    "plt.scatter(classifierlabels,accuracy,showstd)\n",
    "plt.show()\n",
    "for i in range(len(classifierlabels)):\n",
    "    print(\"Classifier: \", classifierlabels[i], \"Accuracy: \", accuracy[i], \"(+/-\", accuracystd[i], \n",
    "          \"%) Precision: \", precision[i], \" Sensitivity: \", sensitivity[i], \" Specificity: \", specificity[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
